{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10bc2ee",
   "metadata": {
    "id": "AuW-xg_bTsaF"
   },
   "source": [
    "# Week 1: Using CNN's with the Cats vs Dogs Dataset\n",
    "\n",
    "Welcome to the 1st assignment of the course! This week, you will be using the famous `Cats vs Dogs` dataset to train a model that can classify images of dogs from images of cats. For this, you will create your own Convolutional Neural Network in Tensorflow and leverage Keras' image preprocessing utilities.\n",
    "\n",
    "You will also create some helper functions to move the images around the filesystem so if you are not familiar with the `os` module be sure to take a look a the [docs](https://docs.python.org/3/library/os.html).\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd65c4f",
   "metadata": {},
   "source": [
    "_**NOTE:** To prevent errors from the autograder, please avoid editing or deleting non-graded cells in this notebook . Please only put your solutions in between the `### START CODE HERE` and `### END CODE HERE` code comments, and refrain from adding any new cells._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d43abc49",
   "metadata": {
    "id": "dn-6c02VmqiN",
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 19:03:30.434474: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-30 19:03:30.458896: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-30 19:03:30.458917: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-30 19:03:30.459576: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-30 19:03:30.463481: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-30 19:03:30.919463: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0000eebe",
   "metadata": {
    "id": "bLTQd84RUs1j"
   },
   "source": [
    "Download the dataset from its original source by running the cell below. \n",
    "\n",
    "Note that the `zip` file that contains the images is unzipped under the `/tmp` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11c35b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-30 19:00:44--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n",
      "Resolving download.microsoft.com (download.microsoft.com)... 23.212.89.111, 2a02:26f0:3500:f84::317f, 2a02:26f0:3500:f95::317f\n",
      "Connecting to download.microsoft.com (download.microsoft.com)|23.212.89.111|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 824887076 (787M) [application/octet-stream]\n",
      "Saving to: ‘/tmp/cats-and-dogs.zip’\n",
      "\n",
      "/tmp/cats-and-dogs. 100%[===================>] 786.67M  11.2MB/s    in 83s     \n",
      "\n",
      "2024-04-30 19:02:07 (9.49 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [824887076/824887076]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\" \\\n",
    "    -O \"/tmp/cats-and-dogs.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfe8528d",
   "metadata": {
    "id": "3sd9dQWa23aj",
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If the URL doesn't work, visit https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n",
    "# And right click on the 'Download Manually' link to get a new URL to the dataset\n",
    "\n",
    "# Note: This is a very large dataset and will take some time to download\n",
    "\n",
    "local_zip = '/tmp/cats-and-dogs.zip'\n",
    "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd9f52b",
   "metadata": {
    "id": "e_HsUV9WVJHL"
   },
   "source": [
    "Now the images are stored within the `/tmp/PetImages` directory. There is a subdirectory for each class, so one for dogs and one for cats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76034c9d",
   "metadata": {
    "id": "DM851ZmN28J3",
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12500 images of dogs.\n",
      "There are 12500 images of cats.\n"
     ]
    }
   ],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "source_path = '/tmp/PetImages'\n",
    "\n",
    "source_path_dogs = os.path.join(source_path, 'Dog')\n",
    "source_path_cats = os.path.join(source_path, 'Cat')\n",
    "\n",
    "# Deletes all non-image files (there are two .db files bundled into the dataset)\n",
    "!find /tmp/PetImages/ -type f ! -name \"*.jpg\" -exec rm {} +\n",
    "\n",
    "# os.listdir returns a list containing all files under the given path\n",
    "print(f\"There are {len(os.listdir(source_path_dogs))} images of dogs.\")\n",
    "print(f\"There are {len(os.listdir(source_path_cats))} images of cats.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b32b528",
   "metadata": {
    "id": "G7dI86rmRGmC"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "There are 12500 images of dogs.\n",
    "There are 12500 images of cats.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6753b45c",
   "metadata": {
    "id": "iFbMliudNIjW"
   },
   "source": [
    "You will need a directory for cats-v-dogs, and subdirectories for training\n",
    "and validation. These in turn will need subdirectories for 'cats' and 'dogs'. To accomplish this, complete the `create_train_val_dirs` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e6c840a",
   "metadata": {
    "cellView": "code",
    "id": "F-QkLjxpmyK2",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "# Define root directory\n",
    "root_dir = '/tmp/cats-v-dogs'\n",
    "\n",
    "# Empty directory to prevent FileExistsError is the function is run several times\n",
    "if os.path.exists(root_dir):\n",
    "  shutil.rmtree(root_dir)\n",
    "\n",
    "# GRADED FUNCTION: create_train_val_dirs\n",
    "def create_train_val_dirs(root_path):\n",
    "  \"\"\"\n",
    "  Creates directories for the train and test sets\n",
    "  \n",
    "  Args:\n",
    "    root_path (string) - the base directory path to create subdirectories from\n",
    "  \n",
    "  Returns:\n",
    "    None\n",
    "  \"\"\"\n",
    "  ### START CODE HERE\n",
    "  # HINT:\n",
    "  # Use os.makedirs to create your directories with intermediate subdirectories\n",
    "  # Don't hardcode the paths. Use os.path.join to append the new directories to the root_path parameter\n",
    "  os.makedirs(os.path.join(root_path, 'training', 'dogs'))\n",
    "  os.makedirs(os.path.join(root_path, 'training', 'cats'))\n",
    "  os.makedirs(os.path.join(root_path, 'validation', 'dogs'))\n",
    "  os.makedirs(os.path.join(root_path, 'validation', 'cats'))\n",
    "  \n",
    "\n",
    "  ### END CODE HERE\n",
    "\n",
    "  \n",
    "try:\n",
    "  create_train_val_dirs(root_path=root_dir)\n",
    "except FileExistsError:\n",
    "  print(\"You should not be seeing this since the upper directory is removed beforehand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08f735fe",
   "metadata": {
    "id": "5dhtL344OK00",
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/cats-v-dogs/training\n",
      "/tmp/cats-v-dogs/validation\n",
      "/tmp/cats-v-dogs/training/dogs\n",
      "/tmp/cats-v-dogs/training/cats\n",
      "/tmp/cats-v-dogs/validation/dogs\n",
      "/tmp/cats-v-dogs/validation/cats\n"
     ]
    }
   ],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "# Test your create_train_val_dirs function\n",
    "\n",
    "for rootdir, dirs, files in os.walk(root_dir):\n",
    "    for subdir in dirs:\n",
    "        print(os.path.join(rootdir, subdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e13d4e",
   "metadata": {
    "id": "D7A0RK3IQsvg"
   },
   "source": [
    "**Expected Output (directory order might vary):**\n",
    "\n",
    "``` txt\n",
    "/tmp/cats-v-dogs/training\n",
    "/tmp/cats-v-dogs/validation\n",
    "/tmp/cats-v-dogs/training/cats\n",
    "/tmp/cats-v-dogs/training/dogs\n",
    "/tmp/cats-v-dogs/validation/cats\n",
    "/tmp/cats-v-dogs/validation/dogs\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9413f4e5",
   "metadata": {
    "id": "R93T7HdE5txZ"
   },
   "source": [
    "Code the `split_data` function which takes in the following arguments:\n",
    "- SOURCE_DIR: directory containing the files\n",
    "\n",
    "- TRAINING_DIR: directory that a portion of the files will be copied to (will be used for training)\n",
    "- VALIDATION_DIR: directory that a portion of the files will be copied to (will be used for validation)\n",
    "- SPLIT_SIZE: determines the portion of images used for training.\n",
    "\n",
    "The files should be randomized, so that the training set is a random sample of the files, and the validation set is made up of the remaining files.\n",
    "\n",
    "For example, if `SOURCE_DIR` is `PetImages/Cat`, and `SPLIT_SIZE` is .9 then 90% of the images in `PetImages/Cat` will be copied to the `TRAINING_DIR` directory\n",
    "and 10% of the images will be copied to the `VALIDATION_DIR` directory.\n",
    "\n",
    "All images should be checked before the copy, so if they have a zero file length, they will be omitted from the copying process. If this is the case then your function should print out a message such as `\"filename is zero length, so ignoring.\"`. **You should perform this check before the split so that only non-zero images are considered when doing the actual split.**\n",
    "\n",
    "\n",
    "Hints:\n",
    "\n",
    "- `os.listdir(DIRECTORY)` returns a list with the contents of that directory.\n",
    "\n",
    "- `os.path.getsize(PATH)` returns the size of the file\n",
    "\n",
    "- `copyfile(source, destination)` copies a file from source to destination\n",
    "\n",
    "- `random.sample(list, len(list))` shuffles a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c123a7",
   "metadata": {
    "cellView": "code",
    "id": "zvSODo0f9LaU",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "# GRADED FUNCTION: split_data\n",
    "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
    "  \"\"\"\n",
    "  Splits the data into train and test sets\n",
    "  \n",
    "  Args:\n",
    "    SOURCE_DIR (string): directory path containing the images\n",
    "    TRAINING_DIR (string): directory path to be used for training\n",
    "    VALIDATION_DIR (string): directory path to be used for validation\n",
    "    SPLIT_SIZE (float): proportion of the dataset to be used for training\n",
    "    \n",
    "  Returns:\n",
    "    None\n",
    "  \"\"\"\n",
    "\n",
    "  ### START CODE HERE\n",
    "  files = [f for f in os.listdir(SOURCE_DIR) if os.path.isfile(os.path.join(SOURCE_DIR, f)) if os.stat(os.path.join(SOURCE_DIR, f)).st_size > 0]\n",
    "\n",
    "  number_of_files = len(files)\n",
    "  split_index = int(number_of_files * SPLIT_SIZE)\n",
    "\n",
    "  training_files = files[:split_index]\n",
    "  validation_files = files[split_index:]\n",
    "\n",
    "  for file in training_files:\n",
    "    copyfile(os.path.join(SOURCE_DIR, file), os.path.join(TRAINING_DIR, file))\n",
    "  \n",
    "  for file in validation_files:\n",
    "    copyfile(os.path.join(SOURCE_DIR, file), os.path.join(VALIDATION_DIR, file))\n",
    "\n",
    "  \n",
    "\n",
    "  ### END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f488106",
   "metadata": {
    "id": "FlIdoUeX9S-9",
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Original cat's directory has 12500 images\n",
      "Original dog's directory has 12500 images\n",
      "\n",
      "There are 11249 images of cats for training\n",
      "There are 11249 images of dogs for training\n",
      "There are 1250 images of cats for validation\n",
      "There are 1250 images of dogs for validation\n"
     ]
    }
   ],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "# Test your split_data function\n",
    "\n",
    "# Define paths\n",
    "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
    "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
    "\n",
    "TRAINING_DIR = \"/tmp/cats-v-dogs/training/\"\n",
    "VALIDATION_DIR = \"/tmp/cats-v-dogs/validation/\"\n",
    "\n",
    "TRAINING_CATS_DIR = os.path.join(TRAINING_DIR, \"cats/\")\n",
    "VALIDATION_CATS_DIR = os.path.join(VALIDATION_DIR, \"cats/\")\n",
    "\n",
    "TRAINING_DOGS_DIR = os.path.join(TRAINING_DIR, \"dogs/\")\n",
    "VALIDATION_DOGS_DIR = os.path.join(VALIDATION_DIR, \"dogs/\")\n",
    "\n",
    "# Empty directories in case you run this cell multiple times\n",
    "if len(os.listdir(TRAINING_CATS_DIR)) > 0:\n",
    "  for file in os.scandir(TRAINING_CATS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(TRAINING_DOGS_DIR)) > 0:\n",
    "  for file in os.scandir(TRAINING_DOGS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(VALIDATION_CATS_DIR)) > 0:\n",
    "  for file in os.scandir(VALIDATION_CATS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(VALIDATION_DOGS_DIR)) > 0:\n",
    "  for file in os.scandir(VALIDATION_DOGS_DIR):\n",
    "    os.remove(file.path)\n",
    "\n",
    "# Define proportion of images used for training\n",
    "split_size = .9\n",
    "\n",
    "# Run the function\n",
    "# NOTE: Messages about zero length images should be printed out\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, VALIDATION_CATS_DIR, split_size)\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, VALIDATION_DOGS_DIR, split_size)\n",
    "\n",
    "# Check that the number of images matches the expected output\n",
    "\n",
    "# Your function should perform copies rather than moving images so original directories should contain unchanged images\n",
    "print(f\"\\n\\nOriginal cat's directory has {len(os.listdir(CAT_SOURCE_DIR))} images\")\n",
    "print(f\"Original dog's directory has {len(os.listdir(DOG_SOURCE_DIR))} images\\n\")\n",
    "\n",
    "# Training and validation splits\n",
    "print(f\"There are {len(os.listdir(TRAINING_CATS_DIR))} images of cats for training\")\n",
    "print(f\"There are {len(os.listdir(TRAINING_DOGS_DIR))} images of dogs for training\")\n",
    "print(f\"There are {len(os.listdir(VALIDATION_CATS_DIR))} images of cats for validation\")\n",
    "print(f\"There are {len(os.listdir(VALIDATION_DOGS_DIR))} images of dogs for validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb2aedc",
   "metadata": {
    "id": "hvskJNOFVSaz"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "666.jpg is zero length, so ignoring.\n",
    "11702.jpg is zero length, so ignoring.\n",
    "\n",
    "\n",
    "Original cat's directory has 12500 images\n",
    "Original dog's directory has 12500 images\n",
    "\n",
    "There are 11249 images of cats for training\n",
    "There are 11249 images of dogs for training\n",
    "There are 1250 images of cats for validation\n",
    "There are 1250 images of dogs for validation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a30ba6",
   "metadata": {
    "id": "Zil4QmOD_mXF"
   },
   "source": [
    "Now that you have successfully organized the data in a way that can be easily fed to Keras' `ImageDataGenerator`, it is time for you to code the generators that will yield batches of images, both for training and validation. For this, complete the `train_val_generators` function below.\n",
    "\n",
    "Something important to note is that the images in this dataset come in a variety of resolutions. Luckily, the `flow_from_directory` method allows you to standarize this by defining a tuple called `target_size` that will be used to convert each image to this target resolution. **For this exercise, use a `target_size` of (150, 150)**.\n",
    "\n",
    "**Hint:** \n",
    "\n",
    "Don't use data augmentation by setting extra parameters when you instantiate the `ImageDataGenerator` class. This will make the training of your model to take longer to reach the necessary accuracy threshold to pass this assignment and this topic will be covered in the next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24714cb2",
   "metadata": {
    "cellView": "code",
    "id": "fQrZfVgz4j2g",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "# GRADED FUNCTION: train_val_generators\n",
    "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
    "  \"\"\"\n",
    "  Creates the training and validation data generators\n",
    "  \n",
    "  Args:\n",
    "    TRAINING_DIR (string): directory path containing the training images\n",
    "    VALIDATION_DIR (string): directory path containing the testing/validation images\n",
    "    \n",
    "  Returns:\n",
    "    train_generator, validation_generator - tuple containing the generators\n",
    "  \"\"\"\n",
    "  ### START CODE HERE\n",
    "\n",
    "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
    "  train_datagen = ImageDataGenerator(\n",
    "                                    rescale=1/255, \n",
    "                                    rotation_range=40, \n",
    "                                    width_shift_range=0.2, \n",
    "                                    height_shift_range=0.2, \n",
    "                                    shear_range=0.2, \n",
    "                                    zoom_range=0.2, \n",
    "                                    horizontal_flip=True, \n",
    "                                    fill_mode='nearest'\n",
    "                                    )\n",
    "\n",
    "  # Pass in the appropriate arguments to the flow_from_directory method\n",
    "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
    "                                                      batch_size=64,\n",
    "                                                      class_mode=\"binary\",\n",
    "                                                      target_size=(150, 150))\n",
    "\n",
    "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
    "  validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "  # Pass in the appropriate arguments to the flow_from_directory method\n",
    "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
    "                                                                batch_size=64,\n",
    "                                                                class_mode=\"binary\",\n",
    "                                                                target_size=(150, 150))\n",
    "  ### END CODE HERE\n",
    "  return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a13c894",
   "metadata": {
    "id": "qM7FxrjGiobD",
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22498 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "# Test your generators\n",
    "train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2992173c",
   "metadata": {
    "id": "tiPNmSfZjHwJ"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "Found 22498 images belonging to 2 classes.\n",
    "Found 2500 images belonging to 2 classes.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b01ac22",
   "metadata": {
    "id": "TI3oEmyQCZoO"
   },
   "source": [
    "One last step before training is to define the architecture of the model that will be trained.\n",
    "\n",
    "Complete the `create_model` function below which should return a Keras' `Sequential` model.\n",
    "\n",
    "Aside from defining the architecture of the model, you should also compile it so make sure to use a `loss` function that is compatible with the `class_mode` you defined in the previous exercise, which should also be compatible with the output of your network. You can tell if they aren't compatible if you get an error during training.\n",
    "\n",
    "**Note that you should use at least 3 convolution layers to achieve the desired performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2141d195",
   "metadata": {
    "cellView": "code",
    "id": "oDPK8tUB_O9e",
    "lines_to_next_cell": 2,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "# GRADED FUNCTION: create_model\n",
    "def create_model():\n",
    "  # DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n",
    "  # USE AT LEAST 3 CONVOLUTION LAYERS\n",
    "\n",
    "  ### START CODE HERE\n",
    "\n",
    "  input_layer = tf.keras.layers.Input(shape=(150, 150, 3))\n",
    "  x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "  x = tf.keras.layers.MaxPooling2D(2, 2)(x)\n",
    "  x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "  x = tf.keras.layers.MaxPooling2D(2, 2)(x)\n",
    "  x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "  x = tf.keras.layers.MaxPooling2D(2, 2)(x)\n",
    "  x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu')(x)\n",
    "  x = tf.keras.layers.MaxPooling2D(2, 2)(x)\n",
    "  x = tf.keras.layers.Conv2D(324, (3, 3), activation='relu')(x)\n",
    "  x = tf.keras.layers.MaxPooling2D(2, 2)(x)\n",
    "  x = tf.keras.layers.Flatten()(x)\n",
    "  x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "  x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "  output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "  model = tf.keras.models.Model(input_layer, output_layer, name = \"Cats-vs-Dogs-Model\")\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  \n",
    "  model.compile(optimizer=\"adam\",\n",
    "                loss=\"binary_crossentropy\",\n",
    "                metrics=['accuracy']) \n",
    "    \n",
    "  ### END CODE HERE\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe2ed9f",
   "metadata": {
    "id": "SMFNJZmTCZv6"
   },
   "source": [
    "Now it is time to train your model!\n",
    "\n",
    "**Note:** You can ignore the `UserWarning: Possibly corrupt EXIF data.` warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e54f0371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 19:03:39.460727: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-30 19:03:39.479115: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-30 19:03:39.479151: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87cbef80",
   "metadata": {
    "id": "5qE1G6JB4fMn",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 19:03:39.501671: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-30 19:03:39.501741: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-30 19:03:39.501754: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-30 19:03:39.586771: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-30 19:03:39.586819: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-30 19:03:39.586824: I tensorflow/core/common_runtime/gpu/gpu"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Cats-vs-Dogs-Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 17, 17, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 7, 7, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 5, 5, 324)         746820    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 2, 2, 324)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1296)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              1328128   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2988677 (11.40 MB)\n",
      "Trainable params: 2988677 (11.40 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-30 19:03:39.586844: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-30 19:03:39.586862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13553 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 19:03:42.935510: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-04-30 19:03:43.087107: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-30 19:03:43.430769: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-30 19:03:43.764816: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f0a5af47d10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-30 19:03:43.764851: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Ti SUPER, Compute Capability 8.9\n",
      "2024-04-30 19:03:43.768518: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714496623.826844   19082 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 57/352 [===>..........................] - ETA: 46s - loss: 0.6937 - accuracy: 0.5085"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstop_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Note that this may take some time.\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mEvaluateEpoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get the untrained model\n",
    "model = create_model()\n",
    "\n",
    "class EvaluateEpoch(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>0.95) and (logs.get('val_accuracy')>0.80):\n",
    "      print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "# Train the model\n",
    "# Note that this may take some time.\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=2,\n",
    "                    verbose=1,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=10,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[EvaluateEpoch()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ccc14c",
   "metadata": {
    "id": "VGsaDMc-GMd4"
   },
   "source": [
    "Once training has finished, you can run the following cell to check the training and validation accuracy achieved at the end of each epoch.\n",
    "\n",
    "**To pass this assignment, your model should achieve a training accuracy of at least 95% and a validation accuracy of at least 80%**. If your model didn't achieve these thresholds, try training again with a different model architecture and remember to use at least 3 convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32146607",
   "metadata": {
    "id": "MWZrJN4-65RC",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApYAAAGzCAYAAACVe1cSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6LklEQVR4nO3de5zOdf7/8ec1p2tmzHloUBMZihhsqJDD0v5ICRVDYaRWbXTW0lKUVRaVUstmMSokOayihNjkULaMxCRnJR0YY8ZpzOH9+2O+c+Uyw1zXeM/R4367Xbf6vD+n1+c9VzPP3p+TwxhjBAAAAFwkn7IuAAAAAJUDwRIAAABWECwBAABgBcESAAAAVhAsAQAAYAXBEgAAAFYQLAEAAGAFwRIAAABWECwBAABgBcESQLk1YMAA1a5du1jrjh49Wg6Hw25B5cy+ffvkcDiUlJRUqvtds2aNHA6H1qxZ42rz9GdVUjXXrl1bAwYMsLpNAN4jWALwmsPh8OhzdvAALtb69es1evRopaWllXUpAM7Dr6wLAFDxvP32227Tb731llasWFGgvUGDBhe1n2nTpik3N7dY644cOVLDhw+/qP3Dcxfzs/LU+vXr9dxzz2nAgAGKiIhwm7djxw75+DBWApQ1giUAr/Xt29dteuPGjVqxYkWB9nOdPHlSwcHBHu/H39+/WPVJkp+fn/z8+BVXWi7mZ2WD0+ks0/1XFCdOnFCVKlXKugxUYvzvHYAS0b59ezVq1EhfffWV2rZtq+DgYP3tb3+TJP3nP//Rrbfeqpo1a8rpdCouLk5jxoxRTk6O2zbOvW4v//q8iRMn6s0331RcXJycTqdatGihTZs2ua1b2DWWDodDQ4YM0eLFi9WoUSM5nU41bNhQH3/8cYH616xZo+bNmyswMFBxcXH617/+5fF1m2vXrlXPnj115ZVXyul0KjY2Vo8//rhOnTpV4PhCQkJ08OBBde/eXSEhIapWrZqGDh1aoC/S0tI0YMAAhYeHKyIiQomJiR6dEv7f//4nh8OhWbNmFZi3fPlyORwOffjhh5Kk/fv366GHHtI111yjoKAgRUdHq2fPntq3b1+R+ynsGktPa/7mm280YMAA1alTR4GBgapevboGDhyoI0eOuJYZPXq0nnrqKUnSVVdd5brcIr+2wq6x3LNnj3r27KmoqCgFBwfrxhtv1NKlS92Wyb9e9L333tPYsWN1xRVXKDAwUB07dtSuXbuKPG5v+iwtLU2PP/64ateuLafTqSuuuEL9+/fX4cOHXcucPn1ao0eP1tVXX63AwEDVqFFDd9xxh3bv3u1W77mXmRR27Wr+92v37t3q0qWLQkNDdc8990jy/DsqSd9995169eqlatWqKSgoSNdcc41GjBghSVq9erUcDocWLVpUYL05c+bI4XBow4YNRfYjKg/+dx5AiTly5IhuueUW9e7dW3379lVMTIwkKSkpSSEhIXriiScUEhKiTz/9VM8++6zS09M1YcKEIrc7Z84cZWRk6IEHHpDD4dD48eN1xx13aM+ePUWOnH3++edauHChHnroIYWGhuq1117TnXfeqQMHDig6OlqStHnzZnXu3Fk1atTQc889p5ycHD3//POqVq2aR8c9f/58nTx5Un/5y18UHR2tL7/8UpMnT9aPP/6o+fPnuy2bk5OjTp066YYbbtDEiRO1cuVKvfTSS4qLi9Nf/vIXSZIxRt26ddPnn3+uBx98UA0aNNCiRYuUmJhYZC3NmzdXnTp19N577xVYft68eYqMjFSnTp0kSZs2bdL69evVu3dvXXHFFdq3b5+mTJmi9u3ba/v27V6NNntT84oVK7Rnzx7de++9ql69urZt26Y333xT27Zt08aNG+VwOHTHHXfo+++/19y5c/XKK6+oatWqknTen8kvv/yiVq1a6eTJk3rkkUcUHR2tWbNm6fbbb9f777+vHj16uC0/btw4+fj4aOjQoTp27JjGjx+ve+65R1988cUFj9PTPjt+/LjatGmjlJQUDRw4UNddd50OHz6sJUuW6Mcff1TVqlWVk5Oj2267TatWrVLv3r316KOPKiMjQytWrNC3336ruLg4j/s/X3Z2tjp16qSbbrpJEydOdNXj6Xf0m2++UZs2beTv769Bgwapdu3a2r17tz744AONHTtW7du3V2xsrGbPnl2gT2fPnq24uDi1bNnS67pRgRkAuEiDBw825/46adeunZFkpk6dWmD5kydPFmh74IEHTHBwsDl9+rSrLTEx0dSqVcs1vXfvXiPJREdHm9TUVFf7f/7zHyPJfPDBB662UaNGFahJkgkICDC7du1ytW3ZssVIMpMnT3a1de3a1QQHB5uDBw+62nbu3Gn8/PwKbLMwhR3fiy++aBwOh9m/f7/b8Ukyzz//vNuyf/jDH0yzZs1c04sXLzaSzPjx411t2dnZpk2bNkaSmTlz5gXrefrpp42/v79bn2VmZpqIiAgzcODAC9a9YcMGI8m89dZbrrbVq1cbSWb16tVux3L2z8qbmgvb79y5c40k89lnn7naJkyYYCSZvXv3Fli+Vq1aJjEx0TX92GOPGUlm7dq1rraMjAxz1VVXmdq1a5ucnBy3Y2nQoIHJzMx0Lfvqq68aSWbr1q0F9nU2T/vs2WefNZLMwoULCyyfm5trjDFmxowZRpJ5+eWXz7tMYX1vzO//bZzdr/nfr+HDh3tUd2Hf0bZt25rQ0FC3trPrMSbv++V0Ok1aWpqr7ddffzV+fn5m1KhRBfaDyo1T4QBKjNPp1L333lugPSgoyPXvGRkZOnz4sNq0aaOTJ0/qu+++K3K7CQkJioyMdE23adNGUt6pz6LcfPPNbiM/jRs3VlhYmGvdnJwcrVy5Ut27d1fNmjVdy9WtW1e33HJLkduX3I/vxIkTOnz4sFq1aiVjjDZv3lxg+QcffNBtuk2bNm7HsmzZMvn5+blGMCXJ19dXDz/8sEf1JCQkKCsrSwsXLnS1ffLJJ0pLS1NCQkKhdWdlZenIkSOqW7euIiIi9PXXX3u0r+LUfPZ+T58+rcOHD+vGG2+UJK/3e/b+r7/+et10002utpCQEA0aNEj79u3T9u3b3Za/9957FRAQ4Jr29DvlaZ8tWLBATZo0KTCqJ8l1ecWCBQtUtWrVQvvoYh6ddfbPoLC6z/cd/e233/TZZ59p4MCBuvLKK89bT//+/ZWZman333/f1TZv3jxlZ2cXed01Kh+CJYASc/nll7v9sc63bds29ejRQ+Hh4QoLC1O1atVcf4COHTtW5HbP/SOXHzKPHj3q9br56+ev++uvv+rUqVOqW7dugeUKayvMgQMHNGDAAEVFRbmum2zXrp2kgscXGBhY4HTu2fVIedfx1ahRQyEhIW7LXXPNNR7V06RJE9WvX1/z5s1ztc2bN09Vq1ZVhw4dXG2nTp3Ss88+q9jYWDmdTlWtWlXVqlVTWlqaRz+Xs3lTc2pqqh599FHFxMQoKChI1apV01VXXSXJs+/D+fZf2L7yn1Swf/9+t/bifqc87bPdu3erUaNGF9zW7t27dc0111i96czPz09XXHFFgXZPvqP5obqouuvXr68WLVpo9uzZrrbZs2frxhtv9Pi/GVQeXGMJoMScPSqSLy0tTe3atVNYWJief/55xcXFKTAwUF9//bWGDRvm0SNrfH19C203xpToup7IycnRn/70J6WmpmrYsGGqX7++qlSpooMHD2rAgAEFju989diWkJCgsWPH6vDhwwoNDdWSJUvUp08ftxDz8MMPa+bMmXrsscfUsmVLhYeHy+FwqHfv3iX6KKFevXpp/fr1euqpp9S0aVOFhIQoNzdXnTt3LvFHGOUr7veitPvsfCOX597slc/pdBZ4DJO331FP9O/fX48++qh+/PFHZWZmauPGjXr99de93g4qPoIlgFK1Zs0aHTlyRAsXLlTbtm1d7Xv37i3Dqn532WWXKTAwsNA7gj25S3jr1q36/vvvNWvWLPXv39/VvmLFimLXVKtWLa1atUrHjx93GwHcsWOHx9tISEjQc889pwULFigmJkbp6enq3bu32zLvv/++EhMT9dJLL7naTp8+XawHknta89GjR7Vq1So999xzevbZZ13tO3fuLLBNb04H16pVq9D+yb/UolatWh5v60I87bO4uDh9++23F9xWXFycvvjiC2VlZZ33JrT8kdRzt3/uCOyFePodrVOnjiQVWbck9e7dW0888YTmzp2rU6dOyd/f3+0yC1w6OBUOoFTljwydPRJ05swZ/fOf/yyrktz4+vrq5ptv1uLFi/XTTz+52nft2qWPPvrIo/Ul9+MzxujVV18tdk1dunRRdna2pkyZ4mrLycnR5MmTPd5GgwYNFB8fr3nz5mnevHmqUaOGW7DPr/3cEbrJkyefdzTMRs2F9ZckTZo0qcA285+/6EnQ7dKli7788ku3R92cOHFCb775pmrXrq1rr73W00O5IE/77M4779SWLVsKfSxP/vp33nmnDh8+XOhIX/4ytWrVkq+vrz777DO3+d789+Ppd7RatWpq27atZsyYoQMHDhRaT76qVavqlltu0TvvvKPZs2erc+fOrjv3cWlhxBJAqWrVqpUiIyOVmJioRx55RA6HQ2+//ba1U9E2jB49Wp988olat26tv/zlL8rJydHrr7+uRo0aKTk5+YLr1q9fX3FxcRo6dKgOHjyosLAwLViwwKPrP8+na9euat26tYYPH659+/bp2muv1cKFC72+/jAhIUHPPvusAgMDdd999xU4RXrbbbfp7bffVnh4uK699lpt2LBBK1eudD2GqSRqDgsLU9u2bTV+/HhlZWXp8ssv1yeffFLoCHazZs0kSSNGjFDv3r3l7++vrl27FvrA7+HDh2vu3Lm65ZZb9MgjjygqKkqzZs3S3r17tWDBAmtv6fG0z5566im9//776tmzpwYOHKhmzZopNTVVS5Ys0dSpU9WkSRP1799fb731lp544gl9+eWXatOmjU6cOKGVK1fqoYceUrdu3RQeHq6ePXtq8uTJcjgciouL04cffqhff/3V45q9+Y6+9tpruummm3Tddddp0KBBuuqqq7Rv3z4tXbq0wH8L/fv311133SVJGjNmjPediUqBYAmgVEVHR+vDDz/Uk08+qZEjRyoyMlJ9+/ZVx44dXc9TLGvNmjXTRx99pKFDh+qZZ55RbGysnn/+eaWkpBR517q/v78++OADPfLII3rxxRcVGBioHj16aMiQIWrSpEmx6vHx8dGSJUv02GOP6Z133pHD4dDtt9+ul156SX/4wx883k5CQoJGjhypkydPFnqa8tVXX5Wvr69mz56t06dPq3Xr1lq5cmWxfi7e1Dxnzhw9/PDDeuONN2SM0f/7f/9PH330kdtd+ZLUokULjRkzRlOnTtXHH3+s3Nxc7d27t9BgGRMTo/Xr12vYsGGaPHmyTp8+rcaNG+uDDz7Qrbfe6vXxnI+nfRYSEqK1a9dq1KhRWrRokWbNmqXLLrtMHTt2dN1c4+vrq2XLlmns2LGaM2eOFixYoOjoaN10002Kj493bWvy5MnKysrS1KlT5XQ61atXL02YMKHIm2zyefMdbdKkiTZu3KhnnnlGU6ZM0enTp1WrVi316tWrwHa7du2qyMhI5ebm6vbbb/e2K1FJOEx5GiYAgHKse/fu2rZtW6HX/wGXuuzsbNWsWVNdu3bV9OnTy7oclBGusQSAQpz7arudO3dq2bJlat++fdkUBJRzixcv1m+//eZ2QxAuPYxYAkAhatSo4Xp/9f79+zVlyhRlZmZq8+bNqlevXlmXB5QbX3zxhb755huNGTNGVatWLfZD7VE5cI0lABSic+fOmjt3rn7++Wc5nU61bNlSL7zwAqESOMeUKVP0zjvvqGnTpkpKSirrclDGGLEEAACAFVxjCQAAACsIlgAAALCCayxRanJzc/XTTz8pNDTUq1ezAQCAsmOMUUZGhmrWrFnkywUIlig1P/30k2JjY8u6DAAAUAw//PCD64H+50OwRKkJDQ2VlPfFDAsLK+NqAACAJ9LT0xUbG+v6O34hBEuUmvzT32FhYQRLAAAqGE8uY+PmHQAAAFhBsAQAAIAVBEsAAABYQbAEAACAFQRLAAAAWEGwBAAAgBUESwAAAFhBsAQAAIAVBEsAAABYUerBsn379nrsscdc07Vr19akSZMuuI7D4dDixYsvet+2tgMAAICCPA6WXbt2VefOnQudt3btWjkcDn3zzTdeF7Bp0yYNGjTI6/UuZPTo0WratGmB9kOHDumWW26xuq/zOXXqlKKiolS1alVlZmaWyj4BAADKksfB8r777tOKFSv0448/Fpg3c+ZMNW/eXI0bN/a6gGrVqik4ONjr9YqjevXqcjqdpbKvBQsWqGHDhqpfv36Zj5IaY5SdnV2mNQAAgMrP42B52223qVq1akpKSnJrP378uObPn6/77rtPR44cUZ8+fXT55ZcrODhY8fHxmjt37gW3e+6p8J07d6pt27YKDAzUtddeqxUrVhRYZ9iwYbr66qsVHBysOnXq6JlnnlFWVpYkKSkpSc8995y2bNkih8Mhh8PhqvncU+Fbt25Vhw4dFBQUpOjoaA0aNEjHjx93zR8wYIC6d++uiRMnqkaNGoqOjtbgwYNd+7qQ6dOnq2/fvurbt6+mT59eYP62bdt02223KSwsTKGhoWrTpo12797tmj9jxgw1bNhQTqdTNWrU0JAhQyRJ+/btk8PhUHJysmvZtLQ0ORwOrVmzRpK0Zs0aORwOffTRR2rWrJmcTqc+//xz7d69W926dVNMTIxCQkLUokULrVy50q2uzMxMDRs2TLGxsXI6napbt66mT58uY4zq1q2riRMnui2fnJwsh8OhXbt2FTjGzMxMpaenu30AAEDl5XGw9PPzU//+/ZWUlCRjjKt9/vz5ysnJUZ8+fXT69Gk1a9ZMS5cu1bfffqtBgwapX79++vLLLz3aR25uru644w4FBAToiy++0NSpUzVs2LACy4WGhiopKUnbt2/Xq6++qmnTpumVV16RJCUkJOjJJ59Uw4YNdejQIR06dEgJCQkFtnHixAl16tRJkZGR2rRpk+bPn6+VK1e6Aly+1atXa/fu3Vq9erVmzZqlpKSkAuH6XLt379aGDRvUq1cv9erVS2vXrtX+/ftd8w8ePKi2bdvK6XTq008/1VdffaWBAwe6RhWnTJmiwYMHa9CgQdq6dauWLFmiunXretSHZxs+fLjGjRunlJQUNW7cWMePH1eXLl20atUqbd68WZ07d1bXrl114MAB1zr9+/fX3Llz9dprryklJUX/+te/FBISIofDoYEDB2rmzJlu+5g5c6batm1baH0vvviiwsPDXZ/Y2FivjwEAAFQgxgspKSlGklm9erWrrU2bNqZv377nXefWW281Tz75pGu6Xbt25tFHH3VN16pVy7zyyivGGGOWL19u/Pz8zMGDB13zP/roIyPJLFq06Lz7mDBhgmnWrJlretSoUaZJkyYFljt7O2+++aaJjIw0x48fd81funSp8fHxMT///LMxxpjExERTq1Ytk52d7VqmZ8+eJiEh4by1GGPM3/72N9O9e3fXdLdu3cyoUaNc008//bS56qqrzJkzZwpdv2bNmmbEiBGFztu7d6+RZDZv3uxqO3r0qNvPZfXq1UaSWbx48QXrNMaYhg0bmsmTJxtjjNmxY4eRZFasWFHosgcPHjS+vr7miy++MMYYc+bMGVO1alWTlJRU6PKnT582x44dc31++OEHI8kcO3asyLoAAED5cOzYMY//fnt1V3j9+vXVqlUrzZgxQ5K0a9curV27Vvfdd58kKScnR2PGjFF8fLyioqIUEhKi5cuXu42IXUhKSopiY2NVs2ZNV1vLli0LLDdv3jy1bt1a1atXV0hIiEaOHOnxPs7eV5MmTVSlShVXW+vWrZWbm6sdO3a42ho2bChfX1/XdI0aNfTrr7+ed7s5OTmaNWuW+vbt62rr27evkpKSlJubKynv9HGbNm3k7+9fYP1ff/1VP/30kzp27OjV8RSmefPmbtPHjx/X0KFD1aBBA0VERCgkJEQpKSmuvktOTpavr6/atWtX6PZq1qypW2+91fXz/+CDD5SZmamePXsWurzT6VRYWJjbBwAAVF5eP27ovvvu04IFC5SRkaGZM2cqLi7OFUQmTJigV199VcOGDdPq1auVnJysTp066cyZM9YK3rBhg+655x516dJFH374oTZv3qwRI0ZY3cfZzg1/DofDFRALs3z5ch08eFAJCQny8/OTn5+fevfurf3792vVqlWSpKCgoPOuf6F5kuTjk/cjM2ddjnC+az7PDs2SNHToUC1atEgvvPCC1q5dq+TkZMXHx7v6rqh9S9L999+vd999V6dOndLMmTOVkJBQajdfAQCA8s3rYNmrVy/5+Phozpw5euuttzRw4EA5HA5J0rp169StWzf17dtXTZo0UZ06dfT99997vO0GDRrohx9+0KFDh1xtGzdudFtm/fr1qlWrlkaMGKHmzZurXr16btcvSlJAQIBycnKK3NeWLVt04sQJV9u6devk4+Oja665xuOazzV9+nT17t1bycnJbp/evXu7buJp3Lix1q5dW2ggDA0NVe3atV0h9FzVqlWTJLc+OvtGngtZt26dBgwYoB49eig+Pl7Vq1fXvn37XPPj4+OVm5ur//73v+fdRpcuXVSlShVNmTJFH3/8sQYOHOjRvgEAQOXndbAMCQlRQkKCnn76aR06dEgDBgxwzatXr55WrFih9evXKyUlRQ888IB++eUXj7d988036+qrr1ZiYqK2bNmitWvXasSIEW7L1KtXTwcOHNC7776r3bt367XXXtOiRYvclqldu7b27t2r5ORkHT58uNDnSN5zzz0KDAxUYmKivv32W61evVoPP/yw+vXrp5iYGO865f/89ttv+uCDD5SYmKhGjRq5ffr376/FixcrNTVVQ4YMUXp6unr37q3//e9/2rlzp95++23XKfjRo0frpZde0muvvaadO3fq66+/1uTJkyXljSreeOONrpty/vvf/2rkyJEe1VevXj0tXLhQycnJ2rJli+6++2630dfatWsrMTFRAwcO1OLFi7V3716tWbNG7733nmsZX19fDRgwQE8//bTq1atX6KUKAADg0lSsN+/cd999Onr0qDp16uR2PeTIkSN13XXXqVOnTmrfvr2qV6+u7t27e16Mj48WLVqkU6dO6frrr9f999+vsWPHui1z++236/HHH9eQIUPUtGlTrV+/Xs8884zbMnfeeac6d+6sP/7xj6pWrVqhjzwKDg7W8uXLlZqaqhYtWuiuu+5Sx44d9frrr3vXGWd56623VKVKlUKvj+zYsaOCgoL0zjvvKDo6Wp9++qmOHz+udu3aqVmzZpo2bZrrtHtiYqImTZqkf/7zn2rYsKFuu+027dy507WtGTNmKDs7W82aNdNjjz2mv//97x7V9/LLLysyMlKtWrVS165d1alTJ1133XVuy0yZMkV33XWXHnroIdWvX19//vOf3UZ1pbyf/5kzZ3Tvvfd620UAAKASc5izL9YDPLB27Vp17NhRP/zwg1eju+np6QoPD9exY8e4kQcAgArCm7/ffqVUEyqBzMxM/fbbbxo9erR69uxZ7EsGAABA5VSsU+G4NM2dO1e1atVSWlqaxo8fX9blAACAcoZT4Sg1nAoHAKDi8ebvNyOWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsMKvrAsAAACAZ3JzpfR0KTVVOnIk759nf7KypOefL7v6CJYAAAClLDdXSksrGAwLC4tntx09mrfu+Tid0nPPSQ5HqR2KG4IlAABAMeXk/B4QCwuF52s/elQypvj7rVJFiooq+ImOzguevr7WDtErBEsAAHDJy87OC3uehMKz29PSLm6/ISHuofB8YfHs6chIKTDQymFbR7AEAACVRlaWe0As6tRy/ufYsYvbb2ho4cHwQmExMlIKCLBz3OUFwRIAAJQ7Z84UPlJYVFjMyLi4/YaHFx0MCxtB9Pe3c9wVHcESAACUmMxM704t53+OH7+4/UZEeH5qOb8tIkLyIxldFLoPAAAU6fRp704t57efPFn8fToceaOBnp5azv/3iIiyu3nlUkewBADgEmGMdOqU94+4SU3NW6+4fHx+D4ieXocYHZ13WtqHV7lUKARLAAAqGGPyRgK9fcTNkSN5p6aLy9fXu5tT8v89LIyAeKkgWAIAUEaMybuW0NtH3KSm5t3cUlx+ft4/4iY/IJbVg7dRMRAsAQC4SMbk3Y3s7SNu8l/BV1z+/t4/4iYqKu/ZiQRElASCJQAA/8eYvOcZevuIm9TUvDewFFdAgHsY9DQsVqlCQET5QrAEAFQ6ubnuAdHT6xCPHr24gBgYWLwRxKAgAiIqB4IlAKDcysnJC4jePuLmYt/DHBzs/UOy8wMicCkjWAIASlx2dt47lb19xE1a2sUFxCpVvLs5Jf9TXt/DDJR3BEsAgMeys/NGA719xI2N9zB7+4ibyEjJ6bRz3AA8Q7AEgEvQmTN5AdHbR9ykp1/cfsPCvDu1nP/hPcxAxUCwBIAKLDPz94DozXWIGRkXt9+ICM/fnnL2a/YIiEDlRrAEgHIg/z3M3j7i5sSJ4u/T4fg9IHpzHWJERN4DtgHgXPxqAACLzn4PszfXIZ48Wfx9nv0eZm+uQwwPz3tFHwDYQrAEgHMYkxcQvX3ETWpq3shjcfn4FO8RN+HhvIcZQPlAsARQaRmTd6rY20fcpKbmXbtYXGe/h9mb6xBDQwmIQKVmTN6jFc6cyftkZbn/s6g2T+b7+Ehjx5bZIRIsAZR7xkjHj3v/iJuLfQ+zn1/Rr9krrD00lLeoACUuJ+fiQ1hpz7+YX0iecjoJlgAuDcbkPa7G20fcpKbm/U9+cQUEeP+Im+ho3sOMS4QxeYGnvIWwoubn5pZ1z9nh55f3S8rfP++fZ/97YW1FzS/jh7cSLAF4LTf394Do6anl/NfsXcx7mJ3OgkHQk7AYHExARCnJySn7EObtOqUxilYaHI4Lh7CLDWwltc1K9suJYAlcwvLfw+ztI26OHr24wYKgIO8fcRMdzXuYLyn5o2gVLaRVllE0f//yHcgKm88jDsoFgiVQCeTk/P4eZm+uQzx69OLfw+ztI24iIwmIpS5/FK28hbALzb+Yax/KEx+fsg9c3q5TCUfRUHoIlkA5kv8eZm8fcZOWdnH7DQnx/hE3UVFlfilP6Tt7FK08hbCi5l/M/z2UJ2UduIqzTUbRcIkhWAIlICvLPSB6eh3isWMXt9/89zB7O4IYEGDnuD1mjPsdneUphF1ofmUZRfP1Ld+BrLD5fn6MogEVAMESuIAzZwofKSwqLF7se5jDw70YQYzIVVRoliJDsuRvPAxJ6Wekw2Uc0irLKFp5CmSenuZkFA1ACSFY4pKQmelJKDRKPWKUmj/vqHT8xMU9rToy6JSigk4pKvCUogJPKCrghKICMhTtn6Eov/S8j+8xRTmOKsonTdE6oojcVPnlZP4ewg6ekfZeIKRVplG08nzdWWHzfX0ZRQOAsxAsUeGdSsvU639arCMng5V6Kkipp4OVeqaKUjNDlJoVoiNZYTqZ68ndIo7/+5zbmqtIHVWUUl2faB1xmy6sLUJp8j2VK52yfshFyw8+FeU0p78/r5wBgEqAYImKz+HQX/+XUORiPspRpI56FApd7b7HFO5/Uj5OT8NXpBQQU7ajaoyiAQDKCMESFV5QmL8GNv9GYcHZigo9o6jQbEWF5yg6IltRESbvGsQoKSzC5/eAGBAg+cdKAXHnD2x+foyiAQDgBYIlKj6HQ9M3NS7rKgAAuOQxHAMAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgCQAAACsIlgAAALCCYAkAAAArCJYAAACwosIGy9q1a2vSpEkeL79mzRo5HA6lpaWVWE0AAACXshIPlg6H44Kf0aNHF2u7mzZt0qBBgzxevlWrVjp06JDCw8OLtb/iqF+/vpxOp37++edS2ycAAEBZKfFgeejQIddn0qRJCgsLc2sbOnSoa1ljjLKzsz3abrVq1RQcHOxxHQEBAapevbocDofXx1Acn3/+uU6dOqW77rpLs2bNKpV9XkhWVlZZlwAAACq5Eg+W1atXd33Cw8PlcDhc0999951CQ0P10UcfqVmzZnI6nfr888+1e/dudevWTTExMQoJCVGLFi20cuVKt+2eeyrc4XDo3//+t3r06KHg4GDVq1dPS5Yscc0/91R4UlKSIiIitHz5cjVo0EAhISHq3LmzDh065FonOztbjzzyiCIiIhQdHa1hw4YpMTFR3bt3L/K4p0+frrvvvlv9+vXTjBkzCsz/8ccf1adPH0VFRalKlSpq3ry5vvjiC9f8Dz74QC1atFBgYKCqVq2qHj16uB3r4sWL3bYXERGhpKQkSdK+ffvkcDg0b948tWvXToGBgZo9e7aOHDmiPn366PLLL1dwcLDi4+M1d+5ct+3k5uZq/Pjxqlu3rpxOp6688kqNHTtWktShQwcNGTLEbfnffvtNAQEBWrVqVYFjzMzMVHp6utsHAABUXuXiGsvhw4dr3LhxSklJUePGjXX8+HF16dJFq1at0ubNm9W5c2d17dpVBw4cuOB2nnvuOfXq1UvffPONunTponvuuUepqannXf7kyZOaOHGi3n77bX322Wc6cOCA2wjqP/7xD82ePVszZ87UunXrlJ6eXiDQFSYjI0Pz589X37599ac//UnHjh3T2rVrXfOPHz+udu3a6eDBg1qyZIm2bNmiv/71r8rNzZUkLV26VD169FCXLl20efNmrVq1Stdff32R+z3X8OHD9eijjyolJUWdOnXS6dOn1axZMy1dulTffvutBg0apH79+unLL790rfP0009r3LhxeuaZZ7R9+3bNmTNHMTExkqT7779fc+bMUWZmpmv5d955R5dffrk6dOhQYP8vvviiwsPDXZ/Y2FivjwEAAFQgphTNnDnThIeHu6ZXr15tJJnFixcXuW7Dhg3N5MmTXdO1atUyr7zyimtakhk5cqRr+vjx40aS+eijj9z2dfToUVctksyuXbtc67zxxhsmJibGNR0TE2MmTJjgms7OzjZXXnml6dat2wVrffPNN03Tpk1d048++qhJTEx0Tf/rX/8yoaGh5siRI4Wu37JlS3PPPfecd/uSzKJFi9zawsPDzcyZM40xxuzdu9dIMpMmTbpgncYYc+utt5onn3zSGGNMenq6cTqdZtq0aYUue+rUKRMZGWnmzZvnamvcuLEZPXp0ocufPn3aHDt2zPX54YcfjCRz7NixIusCAADlw7Fjxzz++10uRiybN2/uNn38+HENHTpUDRo0UEREhEJCQpSSklLkiGXjxo1d/16lShWFhYXp119/Pe/ywcHBiouLc03XqFHDtfyxY8f0yy+/uI0U+vr6qlmzZkUez4wZM9S3b1/XdN++fTV//nxlZGRIkpKTk/WHP/xBUVFRha6fnJysjh07Frmfopzbrzk5ORozZozi4+MVFRWlkJAQLV++3NWvKSkpyszMPO++AwMD3U7tf/311/r22281YMCAQpd3Op0KCwtz+wAAgMrLr6wLkPJC4NmGDh2qFStWaOLEiapbt66CgoJ011136cyZMxfcjr+/v9u0w+FwnV72dHljjJfVu9u+fbs2btyoL7/8UsOGDXO15+Tk6N1339Wf//xnBQUFXXAbRc0vrM7Cbs45t18nTJigV199VZMmTVJ8fLyqVKmixx57zNWvRe1Xyjsd3rRpU/3444+aOXOmOnTooFq1ahW5HgAAqPzKxYjludatW6cBAwaoR48eio+PV/Xq1bVv375SrSE8PFwxMTHatGmTqy0nJ0dff/31BdebPn262rZtqy1btig5Odn1eeKJJzR9+nRJeSOrycnJ573+s3HjxoXeDJOvWrVqbjcZ7dy5UydPnizymNatW6du3bqpb9++atKkierUqaPvv//eNb9evXoKCgq64L7j4+PVvHlzTZs2TXPmzNHAgQOL3C8AALg0lMtgWa9ePS1cuFDJycnasmWL7r777guOPJaUhx9+WC+++KL+85//aMeOHXr00Ud19OjR8z6yKCsrS2+//bb69OmjRo0auX3uv/9+ffHFF9q2bZv69Omj6tWrq3v37lq3bp327NmjBQsWaMOGDZKkUaNGae7cuRo1apRSUlK0detW/eMf/3Dtp0OHDnr99de1efNm/e9//9ODDz5YYPS1MPXq1dOKFSu0fv16paSk6IEHHtAvv/zimh8YGKhhw4bpr3/9q9566y3t3r1bGzdudAXifPfff7/GjRsnY4zb3eoAAODSVi6D5csvv6zIyEi1atVKXbt2VadOnXTdddeVeh3Dhg1Tnz591L9/f7Vs2VIhISHq1KmTAgMDC11+yZIlOnLkSKFhq0GDBmrQoIGmT5+ugIAAffLJJ7rsssvUpUsXxcfHa9y4cfL19ZUktW/fXvPnz9eSJUvUtGlTdejQwe3O7ZdeekmxsbFq06aN7r77bg0dOtSjZ3qOHDlS1113nTp16qT27du7wu3ZnnnmGT355JN69tln1aBBAyUkJBS4TrVPnz7y8/NTnz59ztsXAADg0uMwF3tR4SUkNzdXDRo0UK9evTRmzJiyLqfM7Nu3T3Fxcdq0aZNXgT89PV3h4eE6duwYN/IAAFBBePP3u1zcvFNe7d+/X5988onatWunzMxMvf7669q7d6/uvvvusi6tTGRlZenIkSMaOXKkbrzxxjIZRQYAAOVXuTwVXl74+PgoKSlJLVq0UOvWrbV161atXLlSDRo0KOvSysS6detUo0YNbdq0SVOnTi3rcgAAQDnDqXCUGk6FAwBQ8Xjz95sRSwAAAFhBsAQAAIAVBEsAAABYQbAEAACAFQRLAAAAWMFzLFFq8h9AkJ6eXsaVAAAAT+X/3fbkQUIES5SajIwMSVJsbGwZVwIAALyVkZGh8PDwCy7DcyxRanJzc/XTTz8pNDRUDofD6rbT09MVGxurH374gWdkliD6uXTQz6WHvi4d9HPpKKl+NsYoIyNDNWvWlI/Pha+iZMQSpcbHx0dXXHFFie4jLCyMX1qlgH4uHfRz6aGvSwf9XDpKop+LGqnMx807AAAAsIJgCQAAACsIlqgUnE6nRo0aJafTWdalVGr0c+mgn0sPfV066OfSUR76mZt3AAAAYAUjlgAAALCCYAkAAAArCJYAAACwgmAJAAAAKwiWAAAAsIJgiQrjjTfeUO3atRUYGKgbbrhBX3755QWXnz9/vurXr6/AwEDFx8dr2bJlpVRpxeZNP0+bNk1t2rRRZGSkIiMjdfPNNxf5c0Eeb7/P+d599105HA517969ZAusJLzt57S0NA0ePFg1atSQ0+nU1Vdfze8OD3nb15MmTdI111yjoKAgxcbG6vHHH9fp06dLqdqK57PPPlPXrl1Vs2ZNORwOLV68uMh11qxZo+uuu05Op1N169ZVUlJSidcpA1QA7777rgkICDAzZsww27ZtM3/+859NRESE+eWXXwpdft26dcbX19eMHz/ebN++3YwcOdL4+/ubrVu3lnLlFYu3/Xz33XebN954w2zevNmkpKSYAQMGmPDwcPPjjz+WcuUVi7f9nG/v3r3m8ssvN23atDHdunUrnWIrMG/7OTMz0zRv3tx06dLFfP7552bv3r1mzZo1Jjk5uZQrr3i87evZs2cbp9NpZs+ebfbu3WuWL19uatSoYR5//PFSrrziWLZsmRkxYoRZuHChkWQWLVp0weX37NljgoODzRNPPGG2b99uJk+ebHx9fc3HH39conUSLFEhXH/99Wbw4MGu6ZycHFOzZk3z4osvFrp8r169zK233urWdsMNN5gHHnigROus6Lzt53NlZ2eb0NBQM2vWrJIqsVIoTj9nZ2ebVq1amX//+98mMTGRYOkBb/t5ypQppk6dOubMmTOlVWKl4W1fDx482HTo0MGt7YknnjCtW7cu0TorC0+C5V//+lfTsGFDt7aEhATTqVOnEqzMGE6Fo9w7c+aMvvrqK918882uNh8fH918883asGFDoets2LDBbXlJ6tSp03mXR/H6+VwnT55UVlaWoqKiSqrMCq+4/fz888/rsssu03333VcaZVZ4xennJUuWqGXLlho8eLBiYmLUqFEjvfDCC8rJySmtsiuk4vR1q1at9NVXX7lOl+/Zs0fLli1Tly5dSqXmS0FZ/R30K9GtAxYcPnxYOTk5iomJcWuPiYnRd999V+g6P//8c6HL//zzzyVWZ0VXnH4+17Bhw1SzZs0Cv8zwu+L08+eff67p06crOTm5FCqsHIrTz3v27NGnn36qe+65R8uWLdOuXbv00EMPKSsrS6NGjSqNsiuk4vT13XffrcOHD+umm26SMUbZ2dl68MEH9be//a00Sr4knO/vYHp6uk6dOqWgoKAS2S8jlgCsGDdunN59910tWrRIgYGBZV1OpZGRkaF+/fpp2rRpqlq1almXU6nl5ubqsssu05tvvqlmzZopISFBI0aM0NSpU8u6tEpnzZo1euGFF/TPf/5TX3/9tRYuXKilS5dqzJgxZV0aLhIjlij3qlatKl9fX/3yyy9u7b/88ouqV69e6DrVq1f3ankUr5/zTZw4UePGjdPKlSvVuHHjkiyzwvO2n3fv3q19+/apa9eurrbc3FxJkp+fn3bs2KG4uLiSLboCKs73uUaNGvL395evr6+rrUGDBvr555915swZBQQElGjNFVVx+vqZZ55Rv379dP/990uS4uPjdeLECQ0aNEgjRoyQjw/jXhfrfH8Hw8LCSmy0UmLEEhVAQECAmjVrplWrVrnacnNztWrVKrVs2bLQdVq2bOm2vCStWLHivMujeP0sSePHj9eYMWP08ccfq3nz5qVRaoXmbT/Xr19fW7duVXJysutz++23649//KOSk5MVGxtbmuVXGMX5Prdu3Vq7du1yBXdJ+v7771WjRg1C5QUUp69PnjxZIDzmB3pjTMkVewkps7+DJXprEGDJu+++a5xOp0lKSjLbt283gwYNMhEREebnn382xhjTr18/M3z4cNfy69atM35+fmbixIkmJSXFjBo1iscNecDbfh43bpwJCAgw77//vjl06JDrk5GRUVaHUCF428/n4q5wz3jbzwcOHDChoaFmyJAhZseOHebDDz80l112mfn73/9eVodQYXjb16NGjTKhoaFm7ty5Zs+ePeaTTz4xcXFxplevXmV1COVeRkaG2bx5s9m8ebORZF5++WWzefNms3//fmOMMcOHDzf9+vVzLZ//uKGnnnrKpKSkmDfeeIPHDQFnmzx5srnyyitNQECAuf76683GjRtd89q1a2cSExPdln/vvffM1VdfbQICAkzDhg3N0qVLS7niismbfq5Vq5aRVOAzatSo0i+8gvH2+3w2gqXnvO3n9evXmxtuuME4nU5Tp04dM3bsWJOdnV3KVVdM3vR1VlaWGT16tImLizOBgYEmNjbWPPTQQ+bo0aOlX3gFsXr16kJ/3+b3a2JiomnXrl2BdZo2bWoCAgJMnTp1zMyZM0u8TocxjDkDAADg4nGNJQAAAKwgWAIAAMAKgiUAAACsIFgCAADACoIlAAAArCBYAgAAwAqCJQAAAKwgWAIAAMAKgiUAAACsIFgCAADACoIlAAAArPj/OR9XhUjVEyoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.show()\n",
    "print(\"\")\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3288957c",
   "metadata": {
    "id": "NYIaqsN2pav6"
   },
   "source": [
    "You will probably encounter that the model is overfitting, which means that it is doing a great job at classifying the images in the training set but struggles with new data. This is perfectly fine and you will learn how to mitigate this issue in the upcoming week.\n",
    "\n",
    "Before downloading this notebook and closing the assignment, be sure to also download the `history.pkl` file which contains the information of the training history of your model. You can download this file by running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a724b784",
   "metadata": {
    "id": "yWcrc9nZTsHj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_history():\n",
    "  import pickle\n",
    "  from google.colab import files\n",
    "\n",
    "  with open('history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "  files.download('history.pkl')\n",
    "\n",
    "download_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cc8c73",
   "metadata": {},
   "source": [
    "## Download your notebook for grading\n",
    "\n",
    "Along with the `history.pkl` file, you will also need to submit your solution notebook for grading. The following code cells will check if this notebook's grader metadata (i.e. hidden data in the notebook needed for grading) is not modified by your workspace. This will ensure that the autograder can evaluate your code properly. Depending on its output, you will either:\n",
    "\n",
    "* *if the metadata is intact*: Download the current notebook. Click on the File tab on the upper left corner of the screen then click on `Download -> Download .ipynb.` You can name it anything you want as long as it is a valid `.ipynb` (jupyter notebook) file.\n",
    "<br>\n",
    "\n",
    "* *if the metadata is missing*: A new notebook with your solutions will be created on this Colab workspace. It should be downloaded automatically and you can submit that to the grader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b94f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download metadata checker\n",
    "!wget -nc https://storage.googleapis.com/tensorflow-1-public/colab_metadata_checker.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90ed34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colab_metadata_checker\n",
    "\n",
    "# Please see the output of this cell to see which file you need to submit to the grader\n",
    "colab_metadata_checker.run('C2W1_Assignment_fixed.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c4d4df",
   "metadata": {},
   "source": [
    "**Please disregard the following note if the notebook metadata is detected**\n",
    "\n",
    "_Note: Just in case the download fails for the second point above, you can also do these steps:_\n",
    "* _Click the Folder icon on the left side of this screen to open the File Manager._\n",
    "* _Click the Folder Refresh icon in the File Manager to see the latest files in the workspace. You should see a file ending with a `_fixed.ipynb`._\n",
    "* _Right-click on that file to save locally and submit it to the grader._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8787d3a",
   "metadata": {
    "id": "joAaZSWWpbOI"
   },
   "source": [
    "**Congratulations on finishing this week's assignment!**\n",
    "\n",
    "You have successfully implemented a convolutional neural network that classifies images of cats and dogs, along with the helper functions needed to pre-process the images!\n",
    "\n",
    "**Keep it up!**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
